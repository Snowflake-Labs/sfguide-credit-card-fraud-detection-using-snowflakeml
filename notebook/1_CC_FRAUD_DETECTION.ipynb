{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0549990d-647e-420f-a9d1-bb7cfdbc9b45",
   "metadata": {
    "name": "selectpackages",
    "collapsed": false
   },
   "source": "# Credit Card Fraud Detection: Harnessing the Power of Machine Learning in Snowflake ML\n\nThe prerequisite for this notebook is the completion of setup in the other notebook.\n\nTo get started, let's select a few packages that we will need. In the **Packages** drop-down picker in the top right of the UI, search for and add the following packages by clicking on them:\n\n- snowflake-ml-python\n- matplotlib\n- seaborn\n- altair\n\nOnce you add the packages, click the **Start** button! Once it says **Active**, you're ready to run the rest of the Notebook.\nWe will be consuming the features from the Feature Store\n\n### Snowflake ML Feature Store\nA Python SDK for defining, registering, retrieving, and managing features.\n\nEntity: Entities are the underlying objects that features and feature views are associated with. They encapsulate the join keys used for feature lookups. \n\nFeatureView: A feature view is a group of logically-related features that are refreshed on the same schedule.\n"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "import_libs",
    "collapsed": false
   },
   "source": "# Standard library imports\nimport os\nimport time\nimport math\n\n# Third-party library imports\nimport pandas as pd\nimport numpy as np\n\n\n\n# Snowflake library imports\nimport streamlit as st\n\nimport altair as alt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom snowflake.ml.feature_store import (\nFeatureStore,\nFeatureView,\nCreationMode)\n\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.modeling.metrics import (\nroc_auc_score,  \nprecision_score, \nrecall_score, \nconfusion_matrix\n)\nfrom snowflake.ml import dataset\nfrom snowflake.snowpark import functions as F\nfrom snowflake.snowpark import types as T\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n\n# Set the style for the plots\nsns.set(style=\"whitegrid\")\n\n# Custom color palettes\ncolors = {\n    'Non-Fraud Bars': '#4C72B0',\n    'Fraud Bars': '#55A868',\n    'Non-Fraud Line': '#1f77b4',\n    'Fraud Line': '#ff7f0e'\n}",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "47ab20eb-e582-459f-a151-c1aac537e229",
   "metadata": {
    "name": "set_contextfromprior",
    "collapsed": false
   },
   "source": "Set the context for the database and warehouse"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "set_context",
    "collapsed": false
   },
   "source": "\nsession.sql(\"USE ROLE SYSADMIN\").collect()\nsession.sql(\"USE DATABASE CC_FINS_DB\").collect()\nsession.sql(\"USE SCHEMA ANALYTICS\").collect()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f6adc03f-240a-47d5-b347-85c4d2966dd8",
   "metadata": {
    "name": "Spine_DF",
    "collapsed": false
   },
   "source": "Generating Datasets for Training\nWe are now ready to generate our training set. We'll define a spine DataFrame to form the backbone of our generated dataset and pass it into FeatureStore.generate_dataset() along with our Feature Views.\n\nNOTE: The spine serves as a request template and specifies the entities, labels and timestamps (when applicable). The feature store then attaches feature values along the spine using an AS-OF join to efficiently combine and serve the relevant, point-in-time correct feature data."
  },
  {
   "cell_type": "code",
   "id": "cb5d975a-68a4-431d-b148-5669bb69a209",
   "metadata": {
    "language": "python",
    "name": "create_spine_df",
    "collapsed": false
   },
   "outputs": [],
   "source": "session.sql(\"create or replace TABLE TRANSACTIONS_DATA (USER_ID VARCHAR,TRANSACTION_ID VARCHAR(16777216),IS_FRAUD VARCHAR)\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44aaae1e-2d6e-4c3e-8044-a35f4beb235d",
   "metadata": {
    "name": "save_spinetransactions",
    "collapsed": false
   },
   "source": "Save the spine dataframe to a table"
  },
  {
   "cell_type": "code",
   "id": "ae32a534-2538-4499-bb79-6d24dc824bfc",
   "metadata": {
    "language": "python",
    "name": "TRANSACTIONS_DATA",
    "collapsed": false
   },
   "outputs": [],
   "source": "session.sql(\"insert into TRANSACTIONS_DATA(User_ID, Transaction_ID, IS_FRAUD) SELECT distinct User_ID, Transaction_ID, IS_FRAUD FROM CREDITCARD_TRANSACTIONS\").collect()\nTRANSACTIONS_DATA_df = session.table(\"TRANSACTIONS_DATA\")\nTRANSACTIONS_DATA_df.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "581dae10-7515-4f63-beb2-a48aead752b0",
   "metadata": {
    "name": "stats_using_describe",
    "collapsed": false
   },
   "source": "Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset’s distribution."
  },
  {
   "cell_type": "code",
   "id": "1d672cfd-b87b-48c0-a396-ebc9466bd33a",
   "metadata": {
    "language": "python",
    "name": "stats",
    "collapsed": false
   },
   "outputs": [],
   "source": "full_df = session.sql(\"SELECT * FROM CREDITCARD_TRANSACTIONS\")\nfull_df.describe()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bc7dbca-1884-4c9a-bb17-2eaee4e6d616",
   "metadata": {
    "language": "python",
    "name": "list_columns",
    "collapsed": false
   },
   "outputs": [],
   "source": "full_df.columns",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fe18825-72ee-4af7-91ba-d7d4da91c794",
   "metadata": {
    "name": "Chart_fraud_normal",
    "collapsed": false
   },
   "source": "Visualization of the fraud and normal data using a bar chart displayed in Streamlit. Shows the total number of distinct transactions for each fraud category."
  },
  {
   "cell_type": "code",
   "id": "533372f2-1c62-453d-8b9a-2e19660ee2f9",
   "metadata": {
    "language": "python",
    "name": "visualization_stchart",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Load the dataset\ndataset=full_df.toPandas()\n# Group by 'IS_FRAUD' and count distinct TRANSACTION_ID\ndf= TRANSACTIONS_DATA_df.select( F.col(\"TRANSACTION_ID\"),F.col(\"IS_FRAUD\")).groupBy(F.col(\"IS_FRAUD\")) \\\n          .agg(F.count_distinct(F.col(\"TRANSACTION_ID\")).alias(\"TOTAL_FRAUD\")) \n\n\nst.bar_chart(df,x=\"IS_FRAUD\",y=\"TOTAL_FRAUD\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ebe71034-909f-4a69-90c5-e306fd8e456c",
   "metadata": {
    "name": "transaction_amounts",
    "collapsed": false
   },
   "source": "Create a histogram that shows the distribution of transaction amounts, distinguishing between fraudulent and non-fraudulent transactions. \n"
  },
  {
   "cell_type": "code",
   "id": "d38ec496-bd4f-49ce-ad81-3a18e3089314",
   "metadata": {
    "language": "python",
    "name": "DistributionofTransactionAmounts",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\ndataset['IS_FRAUD'] = dataset['IS_FRAUD'].astype(int)\n# Set the style for the plots\nsns.set(style=\"whitegrid\")\n# Background color\nbackground_color = \"#f0f0f0\"  # Light gray\n# 1. Distribution of Transaction Amounts\nplt.figure(figsize=(4,4))\nsns.histplot(data=dataset, x='TRANSACTION_AMOUNT', hue='IS_FRAUD', kde=True, bins=50)\nplt.title('Distribution of Transaction Amounts')\nplt.xlabel('Transaction Amount')\nplt.ylabel('Frequency')\nplt.legend(title='Transaction', loc='upper right', labels=['Normal', 'Fraud'])\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "43c88797-f7d3-4442-bfa7-1bcb46895f6d",
   "metadata": {
    "name": "dist_clicks",
    "collapsed": false
   },
   "source": "Create a histogram that shows the distribution of clicks, distinguishing between fraudulent and non-fraudulent transactions. "
  },
  {
   "cell_type": "code",
   "id": "f1e4feee-00f6-4125-bbf0-31706ab2d6a3",
   "metadata": {
    "language": "python",
    "name": "Clicksandlogins_Distribution",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#CLICKS, LOGIN_PER_HOUR, and PAGES_VISITED Distributions\nsns.set(style=\"whitegrid\")\n\n# Custom color palettes\ncolors = {\n    'Normal Bars': '#4C72B0',\n    'Fraud Bars': '#55A868',\n    'Normal Line': '#1f77b4',\n    'Fraud Line': '#ff7f0e'\n}\n# 4. CLICKS Distribution\nplt.figure(figsize=(4, 4))\nsns.histplot(data=dataset, x='CLICKS', hue='IS_FRAUD', multiple='dodge', kde=True, bins=30)\nplt.title('Clicks Distribution')\nplt.xlabel('Clicks')\nplt.ylabel('Frequency')\nplt.legend(title='Transaction', loc='upper right', labels=['Normal', 'Fraud'])\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e11d72fe-553e-41fa-92e5-7c2883e0ffd6",
   "metadata": {
    "name": "dist_logins",
    "collapsed": false
   },
   "source": "Create a histogram that shows the distribution of logins, distinguishing between fraudulent and non-fraudulent transactions. "
  },
  {
   "cell_type": "code",
   "id": "8434ffc9-cbd7-40de-9936-bcff3284554b",
   "metadata": {
    "language": "python",
    "name": "LOGIN_PER_HOUR",
    "collapsed": false
   },
   "outputs": [],
   "source": "plt.figure(figsize=(4, 4))\nsns.histplot(data=dataset, x='LOGIN_PER_HOUR', hue='IS_FRAUD', multiple='dodge', kde=True, bins=30)\nplt.title('Login Per Hour Distribution')\nplt.xlabel('Login Per Hour')\nplt.ylabel('Frequency')\nplt.legend(title='Is Fraud', loc='upper right', labels=['Non-Fraud', 'Fraud'])\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a0ca0d1-afa7-4349-9b63-4a0b1df702ab",
   "metadata": {
    "name": "dist_timeelapsed",
    "collapsed": false
   },
   "source": "Create a histogram that shows the distribution of time elapsed, distinguishing between fraudulent and non-fraudulent transactions. "
  },
  {
   "cell_type": "code",
   "id": "d4dbda17-190e-408d-a56b-960ec83fa40c",
   "metadata": {
    "language": "python",
    "name": "TimeElapsedDistribution",
    "collapsed": false
   },
   "outputs": [],
   "source": "plt.figure(figsize=(4,4))\nsns.histplot(data=dataset, x='TIME_ELAPSED', hue='IS_FRAUD', kde=True, bins=50)\nplt.title('Time Elapsed Distribution')\nplt.xlabel('Time Elapsed (seconds)')\nplt.ylabel('Frequency')\nplt.legend(title='Is Fraud', loc='upper right', labels=['Non-Fraud', 'Fraud'])\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "045a06b3-3e26-4e68-987f-dadf9dfd01c7",
   "metadata": {
    "name": "dist_location",
    "collapsed": false
   },
   "source": "Create a histogram that shows the distribution of location, distinguishing between fraudulent and non-fraudulent transactions. "
  },
  {
   "cell_type": "code",
   "id": "9a6fcc1c-478e-4f6d-9af6-b906384ac933",
   "metadata": {
    "language": "python",
    "name": "Geographical_Distribution",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n# Define location coordinates\nlocation_coords = {\n    'New York': (40.7128, -74.0060),\n    'Los Angeles': (34.0522, -118.2437),\n    'Chicago': (41.8781, -87.6298),\n    'Houston': (29.7604, -95.3698),\n    'Phoenix': (33.4484, -112.0740),\n    'Philadelphia': (39.9526, -75.1652),\n    'San Antonio': (29.4241, -98.4936),\n    'San Diego': (32.7157, -117.1611),\n    'Dallas': (32.7767, -96.7970),\n    'San Jose': (37.3382, -121.8863),\n    'Moscow': (55.7558, 37.6176)  # Add Moscow coordinates\n}\n\n# Add latitude and longitude based on location\ndataset['LATITUDE'] = dataset['LOCATION'].map(lambda loc: location_coords.get(loc, (None, None))[0])\ndataset['LONGITUDE'] = dataset['LOCATION'].map(lambda loc: location_coords.get(loc, (None, None))[1])\n\n# Filter for plotting\nplt.figure(figsize=(6, 6))\n\n# Plot all locations\nscatter = plt.scatter(dataset['LONGITUDE'], dataset['LATITUDE'], \n                      c=dataset['IS_FRAUD'].map({0: 'purple', 1: 'red'}),\n                      alpha=0.5)\n\n# Create custom legend\npurple_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='purple', markersize=10, label='Normal')\nred_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Fraud')\n\n# Plot details\nplt.title('Geographical Distribution of Transactions')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\n\n# Set legend with custom handles\nplt.legend(handles=[purple_patch, red_patch], title='Transaction Type', loc='upper left', bbox_to_anchor=(1, 1), frameon=True, fontsize='small')\n\nplt.grid(True)\n\n# Set background color for the plot\nplt.gcf().set_facecolor(\"#f0f0f0\")  # Light gray\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "820f773b-8220-47bf-a10e-0206a8bb1ef9",
   "metadata": {
    "name": "FS_Init",
    "collapsed": false
   },
   "source": "## Feature Store\nThe feature store contains feature views for customers and transactions. Model features will be accessed from the feature store.\n\n**Snowflake Feature:** Feature Store (PrPr) - Easily find features that work with your data"
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "Feature_Store",
    "collapsed": false
   },
   "source": "# Access feature views\n\nfs = FeatureStore(\n    session=session,\n    database=\"CC_FINS_DB\",\n    name=\"ANALYTICS\",\n    default_warehouse=\"CC_FINS_WH\",\n    creation_mode=CreationMode.FAIL_IF_NOT_EXIST\n)\n\ncustomer_fv : FeatureView = fs.get_feature_view(\n    name='Customer_Features',\n    version='V9'\n)\nprint(customer_fv)\n\ntrans_fv : FeatureView = fs.get_feature_view(\n    name='Trans_Features',\n    version='V9'\n)\nprint(trans_fv)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bf56b86f-11bf-43a5-a8d5-994adfbdef3a",
   "metadata": {
    "language": "python",
    "name": "create_dataset",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Get transactions dataset and get features from the feature store\ndef create_dataset(spine_df, name):\n    train_dataset = fs.generate_dataset(\n    name=name,\n    spine_df=spine_df,\n    features=[customer_fv, trans_fv]\n    )\n    df = train_dataset.read.to_snowpark_dataframe()\n    return df\n# Split into train/validation/test\n\n\ndatasets = TRANSACTIONS_DATA_df.random_split([.8,.2])\n\n# Build training tables\ntrain_df = create_dataset(datasets[0], \"train\")\nval_df = create_dataset(datasets[1], \"validation\")\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6aabcd42-980f-4e2b-9ed2-bf30779c9c95",
   "metadata": {
    "name": "training_dataset",
    "collapsed": false
   },
   "source": "View the training dataset.\n\nThis contains the columns except for Ids. The Label is included here as this will be specified in the LABEL field during model training. The classification model supports numeric, Boolean, and string data types for features and labels."
  },
  {
   "cell_type": "code",
   "id": "849b67a7-74d3-454b-9505-54d0732ba22e",
   "metadata": {
    "language": "python",
    "name": "view_training_data",
    "collapsed": false
   },
   "outputs": [],
   "source": "train_df.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "732a0b08-a8c7-462f-af04-15c0b75f9a10",
   "metadata": {
    "name": "view_creation",
    "collapsed": false
   },
   "source": "Creating separate views for training and validation to be used with a Binary Classifier. Columns in the inference data that were not present in the training dataset are ignored.\n"
  },
  {
   "cell_type": "code",
   "id": "6ed5a892-8de4-44ee-946d-2fefe2671015",
   "metadata": {
    "language": "python",
    "name": "create_classification_view",
    "collapsed": false
   },
   "outputs": [],
   "source": "\ntrain_df.write.mode(\"overwrite\").save_as_table(\"training_fd_table\")\n\nsession.sql(\"CREATE OR REPLACE VIEW fraud_classification_training_view AS SELECT IS_FRAUD,LATITUDE,LONGITUDE,LOCATION,TOTAL_TRANSACTIONS,STDDEV_TRANSACTION_AMOUNT,NUM_UNIQUE_MERCHANTS, MEAN_WEEKLY_SPENT,MEAN_MONTHLY_SPENT,MEAN_YEARLY_SPENT,TIME_ELAPSED,CLICKS,CUMULATIVE_CLICKS,CUMULATIVE_LOGINS_PER_HOUR FROM training_fd_table\").collect()\n\nval_df.drop(\"IS_FRAUD\").collect()\nval_df.write.mode(\"overwrite\").save_as_table(\"val_fd_table\")\n\nsession.sql(\"CREATE OR REPLACE VIEW fraud_classification_val_view AS SELECT * EXCLUDE IS_FRAUD FROM val_fd_table\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "508c341d-8098-47ec-afdd-4c93cac9f95b",
   "metadata": {
    "language": "sql",
    "name": "APP_Table",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE or replace table CC_APP_TBL AS SELECT * FROM CREDITCARD_TRANSACTIONS WHERE TRANSACTION_ID NOT IN (SELECT DISTINCT TRANSACTION_ID FROM training_fd_table);\nalter table CC_APP_TBL drop column IS_FRAUD;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1b5ee2a-959d-475d-8333-936ccb48500d",
   "metadata": {
    "language": "sql",
    "name": "fraud_classification_val_view",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM fraud_classification_val_view LIMIT 2;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3db877e6-45bd-4154-b3fb-f7ac40acb2bc",
   "metadata": {
    "name": "Build_model",
    "collapsed": false
   },
   "source": "## Build the model\nWe can create the classification model by running the following statement"
  },
  {
   "cell_type": "code",
   "id": "6298e68c-89f9-410b-b778-0a428a0095b5",
   "metadata": {
    "language": "sql",
    "name": "create_fraud_classification_model",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE SNOWFLAKE.ML.CLASSIFICATION fraud_classification_model(\n    INPUT_DATA => SYSTEM$REFERENCE('view', 'fraud_classification_training_view'),\n    TARGET_COLNAME => 'IS_FRAUD'\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "85c82676-7320-42ab-b523-6ac355dafaf6",
   "metadata": {
    "name": "view_classification_model",
    "collapsed": false
   },
   "source": "View all classification models, use the SHOW command."
  },
  {
   "cell_type": "code",
   "id": "d9b8fe61-4934-4846-beea-acf855dde9e8",
   "metadata": {
    "language": "sql",
    "name": "show_classification",
    "collapsed": false
   },
   "outputs": [],
   "source": "SHOW SNOWFLAKE.ML.CLASSIFICATION;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d7e33e7a-8de7-4418-a46e-776b834f071c",
   "metadata": {
    "name": "fraud_detection",
    "collapsed": false
   },
   "source": "Run inference (prediction) on a dataset, use the model’s PREDICT method."
  },
  {
   "cell_type": "code",
   "id": "7c3a224d-6218-4aef-b8b0-abba597033fc",
   "metadata": {
    "language": "sql",
    "name": "predict_fraud",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE fraud_predictions AS\nSELECT *,CC_FINS_DB.ANALYTICS.fraud_classification_model!PREDICT(INPUT_DATA => object_construct(*)) as predictions\nfrom fraud_classification_val_view;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "86a8901b-b718-4841-85e5-e12848f80ed9",
   "metadata": {
    "name": "view_frauddetections",
    "collapsed": false
   },
   "source": "View the predictions.The model returns output in the following format. The prediction object includes predicted probabilities for each class and the predicted class based on the maximum predicted probability. The predictions are returned in the same order as the original features were provided."
  },
  {
   "cell_type": "code",
   "id": "df1285fb-557b-4f94-b1c4-2e4add5c9394",
   "metadata": {
    "language": "sql",
    "name": "view_predictions_table",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM fraud_predictions;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "61823c63-bade-4dcc-8669-99a5fa3d9142",
   "metadata": {
    "name": "class_probabilities",
    "collapsed": false
   },
   "source": "In the result set, we see that the model produces both a predicted class denoted by class as well giving us the probability of the respective class membership. Oftentimes, we may want to parse out the probabilities or the prediction directly, and have it in its own column"
  },
  {
   "cell_type": "code",
   "id": "40b4cf5d-9c8c-4ab7-a024-173408f25e84",
   "metadata": {
    "language": "sql",
    "name": "view_prediction",
    "collapsed": false
   },
   "outputs": [],
   "source": "select * EXCLUDE PREDICTIONS,\n        predictions:class::STRING AS class,\n      round(predictions['probability'][class], 3) as probability\nfrom fraud_predictions;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd6f3b97-fcdb-4bf8-952b-8b2afd754519",
   "metadata": {
    "name": "ConfusionMatrix",
    "collapsed": false
   },
   "source": "Now that we have built our classifier, we can begin to evaluate it to better understand both its performance as well as the primary factors within the dataset that were driving the predictions. Follow along below to see the various commands you may run to evalute your own classifier:\n\n# Confusion Matrix & Model Accuracy\nOne of the most common ways of evaluating a classifier is by creating a Confusion Matrix, which allows us to visualize the types of errors that the model is making. Typically, they are used to calculate a classifier's Precision & Recall; which describe both the accuracy of a model when it predicts a certain class of interest (Precision), as well as how many of that specific class of interest were classified (recall)"
  },
  {
   "cell_type": "code",
   "id": "4dd67e8f-30ae-401f-95b6-f416801e63d7",
   "metadata": {
    "language": "sql",
    "name": "SHOW_CONFUSION_MATRIX",
    "collapsed": false
   },
   "outputs": [],
   "source": "CALL fraud_classification_model!SHOW_CONFUSION_MATRIX();",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e39aff4-e6f3-4470-8c43-a7a364b45555",
   "metadata": {
    "name": "show_evaluation_metrics",
    "collapsed": false
   },
   "source": "The show_evaluation_metrics calculates the following False Positive, False Negative, True Positive and True Negative"
  },
  {
   "cell_type": "code",
   "id": "83b3b85e-1222-410e-8665-2b5b49a56bae",
   "metadata": {
    "language": "sql",
    "name": "evaluation_metrics",
    "collapsed": false
   },
   "outputs": [],
   "source": "CALL fraud_classification_model!SHOW_EVALUATION_METRICS();",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d232ba1-6c00-4538-9346-23c1e6ded05e",
   "metadata": {
    "name": "show_threshold_metrics",
    "collapsed": false
   },
   "source": "The show_threshold_metrics provides raw counts and metrics for a specific threshold for each class. This can be used to plot ROC and PR curves or do threshold tuning if desired. The threshold varies from 0 to 1 for each specific class; "
  },
  {
   "cell_type": "code",
   "id": "b8fcb13a-7075-478c-b439-a0242ef07505",
   "metadata": {
    "language": "sql",
    "name": "SHOW_THRESHOLD_METRICS",
    "collapsed": false
   },
   "outputs": [],
   "source": "CALL fraud_classification_model!SHOW_THRESHOLD_METRICS()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a69f3ff5-fee9-40a0-bc49-034ac3fab3f2",
   "metadata": {
    "name": "Feature_Importance",
    "collapsed": false
   },
   "source": "# Feature Importances\nThe last thing we want to understand when evaluating the classifier is to get a sense of the importance of each of the individual input columns or features we made use of. \n\nBetter understand what's driving a model's prediction to give us more insight into the business process we are trying to model out\nEngineer new features or remove ones that are not too impactful to increase the model's performance.\nThe ML Classification function provides a method to do just this, and provides us a ranked list of the relative importance of all the input features, such that their values are between 0 and 1, and the importances across all the features sum to be 1."
  },
  {
   "cell_type": "code",
   "id": "c3754281-6be9-4399-8771-34c77368fa57",
   "metadata": {
    "language": "sql",
    "name": "show_featureimportance",
    "collapsed": false
   },
   "outputs": [],
   "source": "CALL fraud_classification_model!SHOW_FEATURE_IMPORTANCE();",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7319e4d7-7516-4e5d-9270-fcac704774f1",
   "metadata": {
    "name": "Endofnotebook",
    "collapsed": false
   },
   "source": "This completes an end to end model building using Snowflake ML and detection of the fraud using a validation dataset."
  }
 ]
}